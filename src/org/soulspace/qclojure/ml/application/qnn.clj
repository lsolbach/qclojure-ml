(ns org.soulspace.qclojure.ml.application.qnn
  "Quantum Neural Networks (QNN) implementation.
  
  QNNs are parameterized quantum circuits organized in layers that can approximate
  arbitrary functions for both classification and regression tasks. This implementation
  follows Clojure principles of simplicity and data orientation.
  
  Key Features:
  - Layer-based architecture using simple data maps
  - Explicit parameter management per layer
  - Sequential network composition using vectors
  - Integration with existing variational algorithm infrastructure
  - Hardware-compatible quantum operations
  - Support for multiple activation patterns
  
  Design Principles:
  - Layers as data: Each layer is a simple map describing its configuration
  - Explicit parameters: Clear parameter ownership and allocation per layer
  - Functional composition: Networks as vectors of layers processed sequentially
  - Data orientation: All network state represented as plain Clojure data structures
  
  Architecture:
  1. Input encoding layer (feature map)
  2. Hidden quantum layers (parameterized unitaries)
  3. Quantum activation functions (non-linear transformations)
  4. Output measurement layer (classical readout)"
  (:require [clojure.spec.alpha :as s]
            [fastmath.core :as fm]
            [org.soulspace.qclojure.domain.circuit :as circuit]
            [org.soulspace.qclojure.domain.result :as result]
            [org.soulspace.qclojure.domain.observables :as obs]
            [org.soulspace.qclojure.application.backend :as backend]
            [org.soulspace.qclojure.application.algorithm.variational-algorithm :as va]
            [org.soulspace.qclojure.ml.application.encoding :as encoding]
            [org.soulspace.qclojure.ml.application.training :as training]))

;;;
;;; Specs for QNN Layer Types and Network Configuration
;;;

;; Core layer specifications
(s/def ::layer-type #{:input :dense :entangling :activation :measurement :output})
(s/def ::num-qubits pos-int?)
(s/def ::layer-name (s/nilable string?))
(s/def ::activation-type #{:quantum-tanh :quantum-relu :pauli-rotation :none})
(s/def ::feature-map-type ::encoding/feature-map-type)

(s/def ::encoding-options map?)

(s/def ::entangling-pattern #{:linear :circular :all-to-all :custom})
(s/def ::measurement-basis #{:computational :pauli-z :pauli-x :pauli-y})

;; Parameter specifications
(s/def ::parameter-count nat-int?)
(s/def ::parameter-indices (s/coll-of nat-int? :kind vector?))
(s/def ::layer-parameters (s/coll-of number? :kind vector?))
(s/def ::entangling-options map?)
(s/def ::activation-options map?)
(s/def ::measurement-options map?)

;; Layer configuration maps
(s/def ::base-layer
  (s/keys :req-un [::layer-type ::num-qubits ::parameter-count]
          :opt-un [::layer-name ::parameter-indices]))

(s/def ::input-layer
  (s/merge ::base-layer
           (s/keys :req-un [::feature-map-type]
                   :opt-un [::encoding-options])))

(s/def ::dense-layer
  (s/merge ::base-layer
           (s/keys :opt-un [::activation-type])))

(s/def ::entangling-layer
  (s/merge ::base-layer
           (s/keys :req-un [::entangling-pattern]
                   :opt-un [::entangling-options])))

(s/def ::activation-layer
  (s/merge ::base-layer
           (s/keys :req-un [::activation-type]
                   :opt-un [::activation-options])))

(s/def ::measurement-layer
  (s/merge ::base-layer
           (s/keys :req-un [::measurement-basis]
                   :opt-un [::measurement-options])))

;; Complete layer specification 
(defmulti layer-type-dispatch :layer-type)
(defmethod layer-type-dispatch :input [_] ::input-layer)
(defmethod layer-type-dispatch :dense [_] ::dense-layer)
(defmethod layer-type-dispatch :entangling [_] ::entangling-layer)
(defmethod layer-type-dispatch :activation [_] ::activation-layer)
(defmethod layer-type-dispatch :measurement [_] ::measurement-layer)
(defmethod layer-type-dispatch :output [_] ::measurement-layer)

(s/def ::qnn-layer (s/multi-spec layer-type-dispatch :layer-type))

;; Network specifications
(s/def ::qnn-network (s/coll-of ::qnn-layer :kind vector? :min-count 1))
(s/def ::total-parameters pos-int?)
(s/def ::parameter-map (s/map-of keyword? ::layer-parameters))

(s/def ::qnn-config
  (s/keys :req-un [::qnn-network ::total-parameters]
          :opt-un [::parameter-map ::training/training-data]))

;;;
;;; Layer Parameter Counting and Allocation
;;;
(defn count-layer-parameters
  "Count the number of parameters needed for a specific layer type.
  
  Parameters:
  - layer: Layer configuration map
  
  Returns:
  Number of parameters required for this layer"
  [layer]
  (case (:layer-type layer)
    :input 0  ; Input layers typically don't have trainable parameters

    :dense
    ;; Dense layer: 3 parameters per qubit (Rx, Ry, Rz rotations)
    (* 3 (:num-qubits layer))

    :entangling
    ;; Entangling layer: parameters depend on pattern
    (case (:entangling-pattern layer :linear)  ; Default to :linear
      :linear (max 0 (dec (:num-qubits layer)))  ; n-1 CNOT gates
      :circular (:num-qubits layer)              ; n CNOT gates (circular)
      :all-to-all (let [n (:num-qubits layer)]  ; all pairs
                    (* n (dec n)))
      :custom (or (:custom-parameter-count layer) 0)
      (max 0 (dec (:num-qubits layer))))  ; Default to linear pattern

    :activation
    ;; Activation layer: depends on activation type
    (case (:activation-type layer :quantum-tanh)  ; Default to :quantum-tanh
      :quantum-tanh (:num-qubits layer)    ; 1 parameter per qubit
      :quantum-relu (:num-qubits layer)    ; 1 parameter per qubit  
      :pauli-rotation (* 3 (:num-qubits layer))  ; 3 parameters per qubit
      :none 0
      (:num-qubits layer))  ; Default to 1 parameter per qubit

    :measurement 0  ; Measurement layers don't have trainable parameters
    :output 0       ; Output layers don't have trainable parameters
    0))

(defn allocate-parameters
  "Allocate parameter indices for each layer in a QNN network.
  
  Parameters:
  - network: Vector of layer configuration maps
  
  Returns:
  Map with :network (updated with parameter indices) and :total-parameters"
  [network]
  {:pre [(s/valid? ::qnn-network network)]}
  (let [layers-with-params
        (reduce
         (fn [{:keys [updated-layers param-index]} layer]
           (let [param-count (count-layer-parameters layer)
                 param-indices (when (pos? param-count)
                                 (vec (range param-index (+ param-index param-count))))
                 updated-layer (cond-> layer
                                 true (assoc :parameter-count param-count)
                                 param-indices (assoc :parameter-indices param-indices))]
             {:updated-layers (conj updated-layers updated-layer)
              :param-index (+ param-index param-count)}))
         {:updated-layers [] :param-index 0}
         network)]
    {:network (:updated-layers layers-with-params)
     :total-parameters (:param-index layers-with-params)}))

;;;
;;; Layer Implementation Functions
;;;
(defn apply-input-layer
  "Apply input layer (feature encoding) to a quantum circuit.
  
  Parameters:
  - circuit: Input quantum circuit
  - layer: Input layer configuration
  - feature-data: Classical feature vector to encode
  - parameters: Not used for input layers
  
  Returns:
  Quantum circuit with encoded features"
  [circuit layer feature-data _parameters]
  {:pre [(s/valid? ::input-layer layer)]}
  (let [feature-map-type (:feature-map-type layer)
        encoding-options (:encoding-options layer {})
        num-qubits (:num-qubits layer)]

    (case feature-map-type
      :angle
      (let [encoding-result (encoding/angle-encoding feature-data num-qubits
                                                     (:gate-type encoding-options :ry))]
        (if (:success encoding-result)
          ((:result encoding-result) circuit)
          (throw (ex-info "Feature encoding failed" encoding-result))))

      :amplitude
      (let [encoding-result (encoding/amplitude-encoding feature-data num-qubits)]
        (if (:success encoding-result)
          ;; For amplitude encoding, we need to create a circuit that prepares the state
          ;; This is simplified - in practice, we'd need state preparation circuits
          (let [fallback-result (encoding/angle-encoding feature-data num-qubits :ry)]
            (if (:success fallback-result)
              ((:result fallback-result) circuit)
              (throw (ex-info "Amplitude encoding fallback failed" fallback-result))))
          (throw (ex-info "Amplitude encoding failed" encoding-result))))

      :basis
      (let [binary-data (mapv #(if (> % 0.5) 1 0) feature-data)
            encoding-result (encoding/basis-encoding binary-data num-qubits)]
        (if (:success encoding-result)
          ;; Create circuit that prepares the basis state
          (reduce (fn [c i]
                    (if (= 1 (nth binary-data i))
                      (circuit/x-gate c i)
                      c))
                  circuit
                  (range (min (count binary-data) num-qubits)))
          (throw (ex-info "Basis encoding failed" encoding-result))))

      :iqp
      (let [iqp-encoder (encoding/iqp-encoding feature-data num-qubits)]
        (iqp-encoder circuit))

      (throw (ex-info "Unsupported feature map type" {:type feature-map-type})))))

(defn apply-dense-layer
  "Apply dense quantum layer with parameterized rotations.
  
  Parameters:
  - circuit: Input quantum circuit
  - layer: Dense layer configuration
  - feature-data: Not used for dense layers
  - parameters: Parameter vector for this layer
  
  Returns:
  Quantum circuit with applied dense transformations"
  [circuit layer _feature-data parameters]
  {:pre [(s/valid? ::dense-layer layer)
         (= (count parameters) (:parameter-count layer))]}
  (let [num-qubits (:num-qubits layer)]
    ;; Apply Rx, Ry, Rz rotations to each qubit using parameters
    (reduce
     (fn [c qubit]
       (let [param-base (* qubit 3)
             rx-angle (nth parameters param-base)
             ry-angle (nth parameters (inc param-base))
             rz-angle (nth parameters (+ param-base 2))]
         (-> c
             (circuit/rx-gate qubit rx-angle)
             (circuit/ry-gate qubit ry-angle)
             (circuit/rz-gate qubit rz-angle))))
     circuit
     (range num-qubits))))

(defn apply-entangling-layer
  "Apply entangling layer with specified connectivity pattern.
  
  Parameters:
  - circuit: Input quantum circuit
  - layer: Entangling layer configuration
  - feature-data: Not used for entangling layers
  - parameters: Parameter vector for this layer (for parameterized entangling)
  
  Returns:
  Quantum circuit with applied entangling operations"
  [circuit layer _feature-data _parameters]
  {:pre [(s/valid? ::entangling-layer layer)]}
  (let [num-qubits (:num-qubits layer)
        pattern (:entangling-pattern layer)]

    (case pattern
      :linear
      ;; Linear connectivity: 0-1, 1-2, 2-3, ...
      (reduce
       (fn [c i]
         (circuit/cnot-gate c i (inc i)))
       circuit
       (range (dec num-qubits)))

      :circular
      ;; Circular connectivity: 0-1, 1-2, ..., (n-1)-0
      (reduce
       (fn [c i]
         (circuit/cnot-gate c i (mod (inc i) num-qubits)))
       circuit
       (range num-qubits))

      :all-to-all
      ;; All-to-all connectivity: every qubit connected to every other
      (reduce
       (fn [c [i j]]
         (circuit/cnot-gate c i j))
       circuit
       (for [i (range num-qubits)
             j (range num-qubits)
             :when (< i j)]
         [i j]))

      :custom
      ;; Custom pattern - would need to be specified in layer configuration
      (let [custom-connections (:custom-connections layer [])]
        (reduce
         (fn [c [control target]]
           (circuit/cnot-gate c control target))
         circuit
         custom-connections))

      ;; Default: no entanglement
      circuit)))

(defn apply-activation-layer
  "Apply quantum activation function to circuit qubits.
  
  Parameters:
  - circuit: Input quantum circuit
  - layer: Activation layer configuration
  - feature-data: Not used for activation layers
  - parameters: Parameter vector for this layer
  
  Returns:
  Quantum circuit with applied activation function"
  [circuit layer _feature-data parameters]
  {:pre [(s/valid? ::activation-layer layer)]}
  (let [num-qubits (:num-qubits layer)
        activation-type (:activation-type layer)]

    (case activation-type
      :quantum-tanh
      ;; Quantum tanh using Ry rotations
      (reduce
       (fn [c qubit]
         (let [angle (nth parameters qubit)]
           (circuit/ry-gate c qubit (fm/tanh angle))))
       circuit
       (range num-qubits))

      :quantum-relu
      ;; Quantum ReLU approximation using conditional rotations
      (reduce
       (fn [c qubit]
         (let [angle (nth parameters qubit)]
           (if (pos? angle)
             (circuit/ry-gate c qubit angle)
             c)))  ; No rotation for negative values
       circuit
       (range num-qubits))

      :pauli-rotation
      ;; General Pauli rotations Rx, Ry, Rz
      (reduce
       (fn [c qubit]
         (let [param-base (* qubit 3)
               rx-angle (nth parameters param-base)
               ry-angle (nth parameters (inc param-base))
               rz-angle (nth parameters (+ param-base 2))]
           (-> c
               (circuit/rx-gate qubit rx-angle)
               (circuit/ry-gate qubit ry-angle)
               (circuit/rz-gate qubit rz-angle))))
       circuit
       (range num-qubits))

      :none
      ;; No activation - pass through
      circuit

      ;; Default: no activation
      circuit)))

(defn apply-measurement-layer
  "Apply measurement operations to circuit (for output layers).
  
  Parameters:
  - circuit: Input quantum circuit
  - layer: Measurement layer configuration
  - feature-data: Not used for measurement layers
  - parameters: Not used for measurement layers
  
  Returns:
  Quantum circuit with measurement operations"
  [circuit layer _feature-data _parameters]
  {:pre [(s/valid? ::measurement-layer layer)]}
  (let [num-qubits (:num-qubits layer)
        measurement-basis (:measurement-basis layer)]

    ;; For now, we'll add the measurement specification to the circuit metadata
    ;; The actual measurement will be handled by the backend during execution
    (case measurement-basis
      :computational
      ;; Standard computational basis measurement (default)
      circuit

      :pauli-z
      ;; Pauli-Z measurement (same as computational)
      circuit

      :pauli-x
      ;; Pauli-X measurement (need to rotate to X basis first)
      (reduce
       (fn [c qubit]
         (circuit/h-gate c qubit))  ; H gate rotates Z basis to X basis
       circuit
       (range num-qubits))

      :pauli-y
      ;; Pauli-Y measurement (need to rotate to Y basis first)
      ;; Using Ry(-œÄ/2) to rotate Z basis to Y basis
      (reduce
       (fn [c qubit]
         (-> c
             (circuit/ry-gate qubit (- (/ fm/PI 2)))  ; Rotate to Y basis
             (circuit/h-gate qubit)))
       circuit
       (range num-qubits))

      ;; Default: computational basis
      circuit)))

;;;
;;; Layer Dispatch Function
;;;
(defn apply-layer
  "Apply a single QNN layer to a quantum circuit.
  
  Parameters:
  - circuit: Input quantum circuit
  - layer: Layer configuration map
  - feature-data: Classical feature data (used only by input layers)
  - layer-parameters: Parameters specific to this layer
  
  Returns:
  Quantum circuit with layer operations applied"
  [circuit layer feature-data layer-parameters]
  {:pre [(s/valid? ::qnn-layer layer)]}
  (case (:layer-type layer)
    :input (apply-input-layer circuit layer feature-data layer-parameters)
    :dense (apply-dense-layer circuit layer feature-data layer-parameters)
    :entangling (apply-entangling-layer circuit layer feature-data layer-parameters)
    :activation (apply-activation-layer circuit layer feature-data layer-parameters)
    :measurement (apply-measurement-layer circuit layer feature-data layer-parameters)
    :output (apply-measurement-layer circuit layer feature-data layer-parameters)
    (throw (ex-info "Unknown layer type" {:layer layer}))))

;;;
;;; Network Composition and Forward Pass
;;;
(defn extract-layer-parameters
  "Extract parameters for a specific layer from the full parameter vector.
  
  Parameters:
  - layer: Layer configuration with parameter indices
  - full-parameters: Complete parameter vector for the network
  
  Returns:
  Parameter vector for this specific layer"
  [layer full-parameters]
  (if-let [indices (:parameter-indices layer)]
    (mapv #(nth full-parameters %) indices)
    []))

(defn apply-qnn-network
  "Apply a complete QNN network to input data, creating a quantum circuit.
  
  This function implements the forward pass of a QNN by sequentially applying
  each layer to the quantum circuit. It handles parameter extraction and
  layer-specific data passing.
  
  Parameters:
  - network: Vector of layer configuration maps (with allocated parameters)
  - feature-data: Classical input feature vector
  - parameters: Complete parameter vector for the entire network
  
  Returns:
  Quantum circuit representing the forward pass of the QNN"
  [network feature-data parameters]
  {:pre [(s/valid? ::qnn-network network)
         (vector? parameters)]}

  (let [;; Start with a base circuit sized for the network
        num-qubits (apply max (map :num-qubits network))
        initial-circuit (circuit/create-circuit num-qubits "QNN Forward Pass")]

    ;; Apply each layer sequentially using reduce
    (reduce
     (fn [circuit layer]
       (let [layer-params (extract-layer-parameters layer parameters)]
         (apply-layer circuit layer feature-data layer-params)))
     initial-circuit
     network)))

(defn create-qnn-circuit-constructor
  "Create a circuit constructor function for QNN integration with variational algorithms.
  
  This function creates a circuit constructor compatible with the variational algorithm
  template. It returns a function that takes parameters and feature data, returning
  a complete QNN circuit.
  
  Parameters:
  - network: QNN network configuration (with allocated parameters)
  
  Returns:
  Function (parameters, feature-data) -> quantum circuit"
  [network]
  {:pre [(s/valid? ::qnn-network network)]}
  (fn qnn-circuit-constructor [parameters feature-data]
    (apply-qnn-network network feature-data parameters)))

(defn qnn-forward-pass
  "Execute the forward pass of a QNN on a quantum backend.
  
  This function executes the complete QNN circuit on a quantum backend using
  the proper backend protocol with result specifications. It returns measurement
  results suitable for both classification and regression tasks.
  
  Production-ready implementation:
  - Uses backend protocol's execute-circuit with result-specs
  - Requests appropriate measurements for the task type
  - Compatible with real quantum hardware and cloud services
  
  Parameters:
  - network: QNN network configuration
  - feature-data: Input feature vector
  - parameters: Network parameter vector
  - backend: Quantum backend implementing QuantumBackend protocol
  - options: Execution options map
  
  Options:
  - :shots - Number of measurement shots (default: 1024)
  - :task-type - :classification or :regression (default: :classification)
  - :measurement-qubits - Qubits to measure (default: all output qubits)
  - :observables - Observables for expectation value measurements (default: Pauli-Z)
  
  Returns:
  Execution result map from backend containing:
  - :results - Result map with measurements, expectations, or probabilities
  - :final-state - Final quantum state (if state-vector available)
  - :execution-metadata - Backend execution metadata"
  [network feature-data parameters backend & {:keys [options] :or {options {}}}]
  {:pre [(s/valid? ::qnn-network network)
         (satisfies? backend/QuantumBackend backend)]}

  (let [circuit (apply-qnn-network network feature-data parameters)
        shots (:shots options 1024)
        task-type (:task-type options :classification)
        num-qubits (:num-qubits circuit)

        ;; Determine what results to request based on task type
        result-specs (case task-type
                       :classification
                       ;; For classification, request measurement counts
                       {:result-specs {:measurements {:shots shots
                                                      :measurement-qubits (or (:measurement-qubits options)
                                                                              (range num-qubits))}}}

                       :regression
                       ;; For regression, request expectation values
                       {:result-specs {:measurements {:shots shots
                                                      :measurement-qubits (or (:measurement-qubits options)
                                                                              (range num-qubits))}}
                        :expectation {:observables (or (:observables options)
                                                       [obs/pauli-z])
                                      :targets [0]}}  ; Measure output qubit

                       ;; Default: measurements only
                       {:result-specs {:measurements {:shots shots}}})

        execution-options (merge options result-specs)]

    ;; Execute circuit using backend protocol
    (try
      (backend/execute-circuit backend circuit execution-options)
      (catch Exception e
        (throw (ex-info "QNN forward pass execution failed"
                        {:network-depth (count network)
                         :num-qubits num-qubits
                         :num-operations (count (:operations circuit))
                         :error-message (.getMessage e)}
                        e))))))

;;;
;;; QNN Network Analysis and Utilities
;;;
(defn analyze-qnn-network
  "Analyze a QNN network configuration and provide insights.
  
  Parameters:
  - network: QNN network configuration
  
  Returns:
  Analysis map with network statistics and insights"
  [network]
  {:pre [(s/valid? ::qnn-network network)]}
  (let [layer-types (map :layer-type network)
        layer-counts (frequencies layer-types)
        total-qubits (apply max (map :num-qubits network))
        total-params (reduce + (map :parameter-count network))
        depth (count network)]

    {:network-structure
     {:depth depth
      :total-qubits total-qubits
      :total-parameters total-params
      :layer-composition layer-counts}

     :layer-analysis
     (mapv (fn [i layer]
             {:layer-index i
              :layer-name (:layer-name layer "Unnamed")
              :layer-type (:layer-type layer)
              :num-qubits (:num-qubits layer)
              :parameter-count (:parameter-count layer)
              :parameter-indices (:parameter-indices layer)})
           (range)
           network)

     :complexity-metrics
     {:parameters-per-qubit (if (pos? total-qubits) (/ total-params total-qubits) 0)
      :layers-per-qubit (if (pos? total-qubits) (/ depth total-qubits) 0)
      :expressivity-score (* depth total-params)  ; Simple heuristic
      :hardware-efficiency (/ (count (filter #(= :entangling (:layer-type %)) network))
                              (max 1 depth))}  ; Ratio of entangling layers

     :recommendations
     (cond-> []
       (> total-params (* 3 total-qubits depth))
       (conj "Consider reducing parameters - high parameter/qubit ratio may lead to overparameterization")

       (< (count (filter #(= :entangling (:layer-type %)) network)) 2)
       (conj "Consider adding more entangling layers for better expressivity")

       (> depth 10)
       (conj "Very deep network - consider gradient issues and hardware noise")

       (= 0 (count (filter #(= :activation (:layer-type %)) network)))
       (conj "No activation layers found - consider adding quantum activation functions"))}))

(defn visualize-qnn-network
  "Create a simple ASCII visualization of the QNN network structure.
  
  Parameters:
  - network: QNN network configuration
  
  Returns:
  String containing ASCII art representation"
  [network]
  {:pre [(s/valid? ::qnn-network network)]}
  (let [max-qubits (apply max (map :num-qubits network))]
    (str
     "QNN Network Visualization:\n"
     "==========================\n\n"
     (apply str
            (map-indexed
             (fn [i layer]
               (let [layer-symbol (case (:layer-type layer)
                                    :input "üì•"
                                    :dense "üî∂"
                                    :entangling "üîó"
                                    :activation "‚ö°"
                                    :measurement "üìä"
                                    :output "üì§"
                                    "‚ùì")
                     param-info (if (pos? (:parameter-count layer))
                                  (format " (%d params)" (:parameter-count layer))
                                  "")]
                 (format "Layer %d: %s %s [%d qubits]%s\n         %s\n\n"
                         i
                         layer-symbol
                         (:layer-type layer)
                         (:num-qubits layer)
                         param-info
                         (or (:layer-name layer) "Unnamed Layer"))))
             network))
     "\nData Flow: Input ‚Üí Dense ‚Üí Entangling ‚Üí Activation ‚Üí ... ‚Üí Measurement\n"
     (format "Total Parameters: %d\n" (reduce + (map :parameter-count network)))
     (format "Network Depth: %d layers\n" (count network))
     (format "Qubit Count: %d\n" max-qubits))))

;;;
;;; QNN Configuration Helpers
;;;
(defn create-feedforward-qnn
  "Create a standard feedforward QNN configuration.
  
  Parameters:
  - num-qubits: Number of qubits in the network
  - hidden-layers: Number of hidden layers
  - feature-map-type: Input encoding type (:angle, :amplitude, etc.)
  - activation-type: Activation function type
  
  Returns:
  Complete QNN network configuration with allocated parameters"
  [num-qubits hidden-layers & {:keys [feature-map-type activation-type]
                               :or {feature-map-type :angle
                                    activation-type :quantum-tanh}}]
  {:pre [(pos-int? num-qubits) (nat-int? hidden-layers)]}

  (let [;; Input layer
        input-layer {:layer-type :input
                     :num-qubits num-qubits
                     :feature-map-type feature-map-type
                     :layer-name "Input Encoding"}

        ;; Hidden layers (dense + entangling + activation)
        hidden-layer-sequence
        (mapcat
         (fn [i]
           [{:layer-type :dense
             :num-qubits num-qubits
             :layer-name (format "Dense Layer %d" (inc i))}
            {:layer-type :entangling
             :num-qubits num-qubits
             :entangling-pattern :linear
             :layer-name (format "Entangling Layer %d" (inc i))}
            {:layer-type :activation
             :num-qubits num-qubits
             :activation-type activation-type
             :layer-name (format "Activation Layer %d" (inc i))}])
         (range hidden-layers))

        ;; Output layer
        output-layer {:layer-type :measurement
                      :num-qubits num-qubits
                      :measurement-basis :computational
                      :layer-name "Output Measurement"}

        ;; Complete network with parameter counts
        add-param-count (fn [layer] (assoc layer :parameter-count (count-layer-parameters layer)))
        network-with-counts (mapv add-param-count
                                  (vec (concat [input-layer] hidden-layer-sequence [output-layer])))

        ;; Complete network
        allocated-result (allocate-parameters network-with-counts)]

    ;; Return just the network part (functions expect vector, not map)
    (:network allocated-result)))

;;;
;;; Layer Dispatch Function (moved here for logical grouping)
;;;
(comment
  ;; Example QNN layer definitions

  ;; Input layer with angle encoding
  (def input-layer
    {:layer-type :input
     :num-qubits 4
     :parameter-count 0
     :feature-map-type :angle
     :encoding-options {:gate-type :ry}
     :layer-name "Input Encoding"})

  ;; Dense quantum layer
  (def dense-layer-1
    {:layer-type :dense
     :num-qubits 4
     :parameter-count 12  ; 3 parameters per qubit
     :activation-type :none
     :layer-name "Dense Layer 1"})

  ;; Entangling layer
  (def entangling-layer
    {:layer-type :entangling
     :num-qubits 4
     :parameter-count 3   ; Linear pattern: 3 CNOT gates
     :entangling-pattern :linear
     :layer-name "Entangling Layer"})

  ;; Activation layer
  (def activation-layer
    {:layer-type :activation
     :num-qubits 4
     :parameter-count 4   ; 1 parameter per qubit for quantum-tanh
     :activation-type :quantum-tanh
     :layer-name "Activation Layer"})

  ;; Output measurement layer
  (def output-layer
    {:layer-type :measurement
     :num-qubits 4
     :parameter-count 0
     :measurement-basis :computational
     :layer-name "Output Measurement"})

  ;; Example QNN network
  (def example-network
    [input-layer
     dense-layer-1
     entangling-layer
     activation-layer
     output-layer])

  ;; Test parameter allocation
  (def allocated-network (allocate-parameters example-network))

  ;; Validate network structure
  (s/valid? ::qnn-network (:network allocated-network))

  ;; Check total parameters
  (:total-parameters allocated-network)  ; Should be 19 parameters total
  
  ;
  )

;;;
;;; QNN Training Integration
;;;
(defn extract-expectation-value
  "Extract expectation value from quantum measurement results.
  
  Production-ready implementation that properly handles result-specs format
  from backend protocol execution. Works with both measurement-based expectations
  and explicit expectation value results.
  
  For classification, computes <Z> expectation on output qubits.
  For regression, uses explicit expectation values from backend.
  
  Parameters:
  - result: Quantum execution result from backend with :results map
  - options: Optional configuration map
    - :observable-index - Index of observable to extract (default: 0)
    - :use-measurements - Compute from measurements vs use explicit expectations
  
  Returns:
  Expectation value as a real number"
  [result & {:keys [options] :or {options {}}}]
  (let [observable-idx (:observable-index options 0)
        results-map (:results result)

        ;; Try explicit expectation values first (from :expectation result-spec)
        expectations (:expectation results-map)
        explicit-value (when expectations
                         (get expectations observable-idx))

        ;; Fall back to computing from measurements if no explicit expectation
        measurements (:measurements results-map)
        outcomes (:outcomes measurements)]

    (cond
      ;; Use explicit expectation value if available
      (some? explicit-value)
      explicit-value

      ;; Compute Z expectation from measurement outcomes
      (and outcomes (seq outcomes))
      (let [total-shots (reduce + (vals outcomes))
            ;; Compute Z expectation: E[Z] = (n_0 - n_1) / total_shots
            ;; Assumes measurement on single output qubit
            n_0 (get outcomes "0" 0)
            n_1 (get outcomes "1" 0)]
        (if (pos? total-shots)
          (double (/ (- n_0 n_1) total-shots))
          0.0))

      ;; No valid results - indicate error
      :else
      (throw (ex-info "Cannot extract expectation value: no valid results available"
                      {:result result
                       :has-expectations (some? expectations)
                       :has-measurements (some? measurements)})))))

(defn extract-probability-distribution
  "Extract probability distribution from quantum measurement results.
  
  Production-ready implementation that properly handles result-specs format
  from backend protocol execution. Converts measurement counts to normalized
  probabilities.
  
  Parameters:
  - result: Quantum execution result from backend with :results map
  - options: Optional configuration map
    - :num-states - Expected number of states (default: infer from outcomes)
    - :normalize - Whether to normalize probabilities (default: true)
  
  Returns:
  Vector of probabilities for each computational basis state, sorted by
  bitstring value (e.g., [p(\"00\"), p(\"01\"), p(\"10\"), p(\"11\")])"
  [result & {:keys [options] :or {options {}}}]
  (let [results-map (:results result)
        measurements (:measurements results-map)
        outcomes (:outcomes measurements)
        total-shots (when outcomes (reduce + (vals outcomes)))
        num-states (:num-states options)
        normalize? (:normalize options true)]

    (cond
      ;; No valid measurement outcomes
      (or (nil? outcomes) (empty? outcomes))
      (throw (ex-info "Cannot extract probability distribution: no measurement outcomes"
                      {:result result
                       :has-results (some? results-map)
                       :has-measurements (some? measurements)}))

      ;; Convert counts to probabilities
      :else
      (let [;; Determine number of states from outcomes or option
            inferred-states (or num-states
                                (count outcomes))

            ;; Build probability vector sorted by bitstring
            state-probs (into (sorted-map)
                              (map (fn [[state count]]
                                     [state (if (and normalize? (pos? total-shots))
                                              (double (/ count total-shots))
                                              count)])
                                   outcomes))

            ;; Convert to vector
            prob-vec (mapv (fn [i]
                             (let [bitstring (format "%s" i)]
                               (get state-probs bitstring 0.0)))
                           (range inferred-states))]

        prob-vec))))

(defn extract-most-probable-state
  "Extract the most probable computational basis state.
  
  Production-ready implementation that properly handles result-specs format
  from backend protocol execution. Finds the bitstring with the highest
  measurement count.
  
  Parameters:
  - result: Quantum execution result from backend with :results map
  - options: Optional configuration map
    - :return-count - Also return the count (default: false)
  
  Returns:
  String representing the most probable bitstring, or
  [bitstring count] if :return-count is true"
  [result & {:keys [options] :or {options {}}}]
  (let [results-map (:results result)
        measurements (:measurements results-map)
        outcomes (:outcomes measurements)
        return-count? (:return-count options false)]

    (cond
      ;; No valid measurement outcomes
      (or (nil? outcomes) (empty? outcomes))
      (throw (ex-info "Cannot extract most probable state: no measurement outcomes"
                      {:result result
                       :has-results (some? results-map)
                       :has-measurements (some? measurements)}))

      ;; Find state with maximum count
      :else
      (let [max-entry (apply max-key val outcomes)
            max-state (key max-entry)
            max-count (val max-entry)]

        (if return-count?
          [max-state max-count]
          max-state)))))

(defn compute-loss
  "Compute loss between prediction and true label.
  
  Parameters:
  - prediction: Model prediction (expectation value, probability vector, or bitstring)
  - label: True label (number for regression, integer for classification)
  - loss-type: Type of loss function
  
  Returns:
  Loss value as a real number"
  [prediction label loss-type]
  (case loss-type
    :mse
    ;; Mean squared error for regression
    (let [pred-value (if (number? prediction) prediction (first prediction))
          diff (- pred-value label)]
      (* diff diff))

    :cross-entropy
    ;; Cross-entropy for classification
    (let [prob-dist (if (vector? prediction) prediction [prediction (- 1.0 prediction)])
          label-idx (int label)
          prob (nth prob-dist label-idx 1e-10)]  ; Avoid log(0)
      (- (Math/log (max prob 1e-10))))

    :hinge
    ;; Hinge loss for binary classification
    (let [pred-value (if (number? prediction) prediction
                         (- (first prediction) (second prediction)))
          label-value (if (= label 0) -1.0 1.0)
          margin (* label-value pred-value)]
      (max 0.0 (- 1.0 margin)))

    :accuracy
    ;; Negative accuracy (for maximization via minimization)
    (let [predicted-label (if (string? prediction)
                            (Integer/parseInt prediction)
                            (if (> (first prediction) 0.5) 1 0))
          correct? (= predicted-label (int label))]
      (if correct? 0.0 1.0))

    ;; Default: MSE
    (let [pred-value (if (number? prediction) prediction (first prediction))
          diff (- pred-value label)]
      (* diff diff))))

(defn create-qnn-cost-function
  "Create a cost function for QNN training compatible with variational algorithms.
  
  This function creates a cost function that takes parameters and returns a loss value.
  It integrates with the QClojure variational algorithm template for optimization.
  
  Parameters:
  - network: QNN network configuration
  - training-data: Vector of {:features [...] :label ...} maps
  - backend: Quantum backend for circuit execution
  - loss-type: Loss function type (:mse, :cross-entropy, :hinge, etc.)
  - options: Training options (shots, measurement strategy, etc.)
  
  Returns:
  Cost function (parameters) -> loss value"
  [network training-data backend loss-type & {:keys [options] :or {options {}}}]
  {:pre [(s/valid? ::qnn-network network)
         (vector? training-data)
         (every? #(and (contains? % :features) (contains? % :label)) training-data)]}

  (let [shots (:shots options 1024)
        measurement-strategy (:measurement-strategy options :expectation)]

    (fn qnn-cost-function [parameters]
      (try
        ;; Compute loss over all training examples
        (let [total-loss
              (reduce
               (fn [acc-loss {:keys [features label]}]
                 (let [;; Execute QNN forward pass
                       result (qnn-forward-pass network features parameters backend :options options)

                       ;; Extract prediction from quantum measurement
                       prediction (case measurement-strategy
                                    :expectation (extract-expectation-value result)
                                    :probability (extract-probability-distribution result)
                                    :bitstring (extract-most-probable-state result)
                                    result)

                       ;; Compute loss for this example
                       example-loss (compute-loss prediction label loss-type)]

                   (+ acc-loss example-loss)))
               0.0
               training-data)

              ;; Average loss over training set
              avg-loss (/ total-loss (count training-data))]

          avg-loss)

        (catch Exception e
          ;; Return high loss for failed evaluations
          (println "Warning: Cost function evaluation failed:" (.getMessage e))
          1e6)))))

(defn optimize-parameters
  "Simple parameter optimization for demonstration.
  
  In a full implementation, this would delegate to QClojure's optimization
  algorithms like Nelder-Mead, COBYLA, or gradient-based methods.
  
  Parameters:
  - cost-fn: Cost function to minimize
  - initial-params: Initial parameter values
  - options: Optimization options
  
  Returns:
  Optimization result map"
  [cost-fn initial-params options]
  (let [max-iter (:max-iterations options 50)
        tolerance (:tolerance options 1e-6)]

    ;; Simple random search for demonstration
    ;; Real implementation would use proper optimization algorithms
    (loop [iteration 0
           best-params initial-params
           best-cost (cost-fn initial-params)
           history []]

      (if (or (>= iteration max-iter)
              (< best-cost tolerance))
        ;; Return optimization result
        {:parameters best-params
         :final-cost best-cost
         :iterations iteration
         :history (conj history {:iteration iteration :cost best-cost})}

        ;; Try random perturbation
        (let [;; Small random perturbations
              perturbation (mapv (fn [_param] (* 0.1 (- (rand 2.0) 1.0))) initial-params)
              new-params (mapv + best-params perturbation)
              new-cost (cost-fn new-params)]

          (if (< new-cost best-cost)
            ;; Accept improvement
            (recur (inc iteration)
                   new-params
                   new-cost
                   (conj history {:iteration iteration :cost new-cost :improvement true}))
            ;; Reject and continue
            (recur (inc iteration)
                   best-params
                   best-cost
                   (conj history {:iteration iteration :cost best-cost :improvement false}))))))))

(defn evaluate-qnn-accuracy
  "Evaluate QNN accuracy on a dataset.
  
  Parameters:
  - network: QNN network configuration
  - test-data: Test dataset
  - parameters: Optimized QNN parameters
  - backend: Quantum backend
  
  Returns:
  Accuracy as a number between 0 and 1"
  [network test-data parameters backend]
  (if (empty? test-data)
    0.0
    (let [correct-predictions
          (reduce
           (fn [correct {:keys [features label]}]
             (try
               (let [result (qnn-forward-pass network features parameters backend)
                     prediction (extract-most-probable-state result)
                     predicted-label (Integer/parseInt prediction)
                     actual-label (int label)]
                 (if (= predicted-label actual-label)
                   (inc correct)
                   correct))
               (catch Exception _e
                 correct)))  ; Count as incorrect if evaluation fails
           0
           test-data)]

      (/ correct-predictions (count test-data)))))

(defn qnn-dataset-constructor
  "Extract training data from QNN options for the variational algorithm template.
  
  This function adapts the QNN data format to work with the variational algorithm template,
  which expects a dataset source.
  
  Parameters:
  - options: QNN training options containing :training-data
  
  Returns:
  Training data vector"
  [options]
  (:training-data options))

(defn qnn-parameter-count
  "Calculate required parameter count for QNN network.
  
  This function determines how many parameters are needed for the complete
  QNN network by summing parameters across all layers.
  
  Parameters:
  - options: QNN training options containing :network
  
  Returns:
  Total number of parameters required"
  [options]
  (let [network (:network options)]
    (reduce + (map :parameter-count network))))

(defn qnn-circuit-constructor-adapter
  "Create circuit constructor function for QNN from options.
  
  This function creates a circuit constructor that works with the enhanced
  variational template. The resulting function takes parameters and a feature
  vector, returning a complete QNN circuit.
  
  Parameters:
  - options: QNN training options containing :network
  
  Returns:
  Function that takes (parameters, feature-vector) and returns a quantum circuit"
  [options]
  (let [network (:network options)]
    (create-qnn-circuit-constructor network)))

(defn qnn-result-processor
  "Process QNN training results with ML-specific metrics.
  
  This processor extracts ML performance metrics from the optimization results
  and adds QNN-specific analysis.
  
  Parameters:
  - optimization-result: Result from variational optimization
  - options: QNN training options
  
  Returns:
  Enhanced result map with QNN metrics"
  [optimization-result options]
  (let [optimal-params (:optimal-parameters optimization-result)
        task-type (:task-type options :classification)
        loss-type (:loss-type options (if (= task-type :classification) :accuracy :mse))
        optimal-loss (if (= task-type :classification)
                       (- (:optimal-energy optimization-result))  ; Convert from negative accuracy
                       (:optimal-energy optimization-result))
        network (:network options)
        training-data (:training-data options)]

    {:success (:success optimization-result)
     :optimal-parameters optimal-params
     :final-loss optimal-loss
     :final-accuracy (when (= task-type :classification) optimal-loss)
     :iterations (:iterations optimization-result)
     :function-evaluations (:function-evaluations optimization-result)
     :convergence-history (:convergence-history optimization-result)
     :total-runtime-ms (:total-runtime-ms optimization-result 0)
     :network-info {:total-parameters (reduce + (map :parameter-count network))
                    :network-depth (count network)
                    :num-qubits (apply max (map :num-qubits network))}
     :training-info {:num-samples (count training-data)
                     :task-type task-type
                     :loss-type loss-type}
     :optimization-method (:optimization-method options :cmaes)}))

(defn qnn-prediction-extractor
  "Extract prediction from QNN measurement result for enhanced template.
  
  This function is designed to work with the enhanced-variational-algorithm template's
  prediction extraction infrastructure. It handles both classification and regression.
  
  Parameters:
  - measurement-result: Measurement result map
  - task-type: Type of ML task (:classification or :regression)
  - measurement-strategy: How to extract predictions (:expectation, :probability, :bitstring)
  - shots: Number of measurement shots
  
  Returns:
  Predicted value (integer for classification, float for regression)"
  [measurement-result task-type measurement-strategy shots]
  (case task-type
    :classification
    (case measurement-strategy
      :bitstring
      ;; Extract most probable state as classification label
      (let [most-probable (extract-most-probable-state measurement-result)]
        (Integer/parseInt most-probable))

      :expectation
      ;; Use expectation value, threshold at 0.5 for binary classification
      (let [expectation (extract-expectation-value measurement-result)]
        (if (> expectation 0.5) 1 0))

      :probability
      ;; Use probability distribution to find most likely class
      (let [probs (extract-probability-distribution measurement-result)
            max-idx (.indexOf probs (apply max probs))]
        max-idx)

      ;; Default: bitstring extraction
      (let [most-probable (extract-most-probable-state measurement-result)]
        (Integer/parseInt most-probable)))
    
    :regression
    (case measurement-strategy
      :expectation
      ;; For regression, use expectation value directly
      (extract-expectation-value measurement-result)

      :probability
      ;; Weighted average of states for regression
      (let [probs (extract-probability-distribution measurement-result)]
        (reduce + (map-indexed (fn [idx prob] (* idx prob)) probs)))

      ;; Default: expectation value
      (extract-expectation-value measurement-result))

    ;; Default: classification with bitstring
    (let [most-probable (extract-most-probable-state measurement-result)]
      (Integer/parseInt most-probable))))

(defn qnn-loss-function
  "Create a loss function for QNN that works with the enhanced variational template.
  
  This function creates loss functions suitable for both classification and regression
  tasks in quantum neural networks. It computes loss based on predictions and labels/targets.
  
  Parameters:
  - loss-type: Type of loss function (:mse, :cross-entropy, :hinge, :accuracy)
  - task-type: Type of ML task (:classification or :regression)
  
  Returns:
  Function that takes (predictions, labels) and returns loss value"
  [loss-type task-type]
  (case task-type
    :classification
    (case loss-type
      :accuracy
      (fn accuracy-loss [predictions labels]
        ;; predictions is a vector of predicted labels (integers)
        ;; labels is a vector of true labels (integers)
        (if (or (empty? predictions) (empty? labels))
          1.0  ; Return maximum loss for empty batches
          (let [correct-count (count (filter true? (map = predictions labels)))
                accuracy (/ correct-count (count labels))]
            ;; Return negative accuracy for minimization
            (- accuracy))))

      :cross-entropy
      (fn cross-entropy-loss [predictions labels]
        ;; For cross-entropy, predictions should be probability distributions
        ;; This is a simplified version - full implementation would need probability vectors
        (if (or (empty? predictions) (empty? labels))
          100.0  ; Return high loss for empty batches
          (let [correct-count (count (filter true? (map = predictions labels)))
                accuracy (/ correct-count (count labels))]
            ;; Return negative log likelihood approximation
            (- (Math/log (max 0.001 accuracy))))))

      :hinge
      (fn hinge-loss [predictions labels]
        ;; Hinge loss for classification
        (if (or (empty? predictions) (empty? labels))
          1.0  ; Return maximum loss for empty batches
          (let [correct-count (count (filter true? (map = predictions labels)))
                accuracy (/ correct-count (count labels))]
            ;; Return negative accuracy (simplified hinge loss)
            (- accuracy))))

      ;; Default to accuracy-based loss
      (fn default-loss [predictions labels]
        (if (or (empty? predictions) (empty? labels))
          1.0  ; Return maximum loss for empty batches
          (let [correct-count (count (filter true? (map = predictions labels)))
                accuracy (/ correct-count (count labels))]
            (- accuracy)))))

    :regression
    (case loss-type
      :mse
      (fn mse-loss [predictions targets]
        ;; Mean squared error for regression
        (if (or (empty? predictions) (empty? targets))
          1000.0  ; Return high loss for empty batches
          (let [squared-errors (map (fn [pred target]
                                      (let [diff (- pred target)]
                                        (* diff diff)))
                                    predictions targets)
                mse (/ (reduce + squared-errors) (count predictions))]
            mse)))

      :mae
      (fn mae-loss [predictions targets]
        ;; Mean absolute error for regression
        (if (or (empty? predictions) (empty? targets))
          1000.0  ; Return high loss for empty batches
          (let [absolute-errors (map (fn [pred target]
                                       (Math/abs (- pred target)))
                                     predictions targets)
                mae (/ (reduce + absolute-errors) (count predictions))]
            mae)))

      ;; Default to MSE
      (fn default-mse-loss [predictions targets]
        (if (or (empty? predictions) (empty? targets))
          1000.0  ; Return high loss for empty batches
          (let [squared-errors (map (fn [pred target]
                                      (let [diff (- pred target)]
                                        (* diff diff)))
                                  predictions targets)
              mse (/ (reduce + squared-errors) (count predictions))]
          mse))))

    ;; Default: assume classification with accuracy loss
    (fn default-accuracy-loss [predictions labels]
      (if (or (empty? predictions) (empty? labels))
        1.0  ; Return maximum loss for empty batches
        (let [correct-count (count (filter true? (map = predictions labels)))
              accuracy (/ correct-count (count labels))]
          (- accuracy))))))

(defn train-qnn
  "Train a QNN using the enhanced variational algorithm template.
  
  This function configures and executes quantum neural network training with support
  for both classification and regression tasks. The QNN is trained using the enhanced
  variational algorithm template with ML-specific objective handling.
  
  The training process:
  1. Encodes training features into quantum states via input layers
  2. Applies parameterized quantum layers (dense, entangling, activation)
  3. Measures results and extracts predictions
  4. Optimizes network parameters to minimize task-specific loss
  
  Parameters:
  - backend: Quantum backend for circuit execution
  - options: Configuration map with required and optional keys
  
  Required options:
  - :network - QNN network configuration (vector of layer maps)
  - :training-data - Vector of {:features [...] :label ...} maps
  
  Optional options (with defaults):
  - :task-type - ML task type (:classification or :regression) [default: :classification]
  - :loss-type - Loss function (:accuracy, :cross-entropy, :hinge, :mse, :mae) 
                 [default: :accuracy for classification, :mse for regression]
  - :measurement-strategy - How to extract predictions (:expectation, :probability, :bitstring)
                           [default: :bitstring for classification, :expectation for regression]
  - :optimization-method - Optimizer to use (:cmaes, :nelder-mead, :powell, :adam)
                          [default: :cmaes]
  - :max-iterations - Maximum training iterations [default: 100]
  - :tolerance - Convergence tolerance [default: 1e-6]
  - :shots - Number of measurement shots [default: 1024]
  - :initial-parameters - Initial parameter values (random if not provided)
  
  Returns:
  Map containing trained model and analysis results:
  - :success - Training completion status
  - :optimal-parameters - Trained network parameters
  - :final-loss - Final loss value
  - :final-accuracy - Final accuracy (for classification tasks)
  - :iterations - Number of iterations performed
  - :convergence-history - Loss values over iterations
  - :total-runtime-ms - Total training time
  - :network-info - Network architecture details
  - :training-info - Training configuration summary
  
  Example:
  ```clojure
  (train-qnn 
    backend
    {:network qnn-network
     :training-data [{:features [0.1 0.2] :label 0}
                     {:features [0.8 0.9] :label 1}]
     :task-type :classification
     :loss-type :accuracy
     :optimization-method :cmaes
     :max-iterations 100
     :shots 1024})"
  [backend options]
  {:pre [(s/valid? ::qnn-network (:network options))
         (vector? (:training-data options))
         (not-empty (:training-data options))]}

  ;; Use enhanced-variational-algorithm template with :classification or :regression objective
  (let [;; Extract configuration
        task-type (:task-type options :classification)
        loss-type (:loss-type options (if (= task-type :classification) :accuracy :mse))
        measurement-strategy (:measurement-strategy options
                                                    (if (= task-type :classification) :bitstring :expectation))
        shots (:shots options 1024)

        ;; Create loss function for the task type
        loss-fn (qnn-loss-function loss-type task-type)

        ;; Create prediction extractor that works with measurement results
        prediction-extractor (fn [measurement-result]
                               (qnn-prediction-extractor measurement-result task-type
                                                         measurement-strategy shots))

        ;; Enhanced options with ML-specific settings
        enhanced-options (merge {:optimization-method :cmaes  ; Use derivative-free by default
                                 :max-iterations 100
                                 :tolerance 1e-6
                                 :shots shots
                                 ;; Parameter ranges for QNN (typically 0 to 2œÄ)
                                 :parameter-range [0.0 6.28]}
                                options)]

    ;; Use variational-algorithm template
    (va/variational-algorithm
     backend
     enhanced-options
     {:algorithm :qnn
      :objective-kind task-type  ; :classification or :regression
      :parameter-count-fn qnn-parameter-count
      :circuit-constructor-fn qnn-circuit-constructor-adapter
      :dataset-fn qnn-dataset-constructor
      :loss-fn loss-fn
      :prediction-extractor-fn prediction-extractor
      :result-processor-fn qnn-result-processor})))

;;;
;;; QNN Model Interface
;;;
(defn create-qnn-model
  "Create a complete QNN model with training and inference capabilities.
  
  This function provides a high-level interface for QNN creation, training,
  and inference, abstracting away the low-level details.
  
  Parameters:
  - config: QNN configuration map
  
  Configuration options:
  - :num-qubits - Number of qubits
  - :hidden-layers - Number of hidden layers
  - :feature-map-type - Input encoding type
  - :activation-type - Activation function type
  
  Returns:
  QNN model map with train and predict functions"
  [config]
  {:pre [(map? config) (contains? config :num-qubits)]}

  (let [num-qubits (:num-qubits config)
        hidden-layers (:hidden-layers config 1)
        feature-map-type (:feature-map-type config :angle)
        activation-type (:activation-type config :quantum-tanh)

        ;; Create the QNN network
        network (create-feedforward-qnn num-qubits hidden-layers
                                        :feature-map-type feature-map-type
                                        :activation-type activation-type)]

    {:network network
     :config config
     :trained-parameters nil
     :training-history nil

     ;; Training function
     :train (fn [training-data backend & {:keys [options] :or {options {}}}]
              (let [training-options (merge options {:network network :training-data training-data})
                    result (train-qnn backend training-options)]
                (if (:success result)
                  (assoc result
                         :trained-parameters (:optimal-parameters result)
                         :training-history (:convergence-history result))
                  result)))

     ;; Prediction function
     :predict (fn [features parameters backend]
                (qnn-forward-pass network features parameters backend))

     ;; Evaluation function
     :evaluate (fn [test-data parameters backend]
                 (evaluate-qnn-accuracy network test-data parameters backend))

     ;; Analysis function
     :analyze (fn [] (analyze-qnn-network network))

     ;; Visualization function
     :visualize (fn [] (visualize-qnn-network network))}))

;;;
;;; Rich Comment Block for Interactive Development
;;;
(comment
  ;; QNN Example: Binary Classification Task
  ;; This example demonstrates building, training, and evaluating a QNN
  ;; for a simple binary classification problem.

  ;; Required namespaces for the example
  (require '[org.soulspace.qclojure.adapter.backend.ideal-simulator :as simulator]
           '[clojure.string :as str])

  ;; Step 1: Create a quantum backend
  (def backend (simulator/create-simulator))

  ;; Step 2: Define a simple binary classification dataset
  ;; Two features per sample, binary labels (0 or 1)
  (def training-data
    [{:features [0.1 0.2] :label 0}
     {:features [0.8 0.9] :label 1}
     {:features [0.2 0.1] :label 0}
     {:features [0.9 0.8] :label 1}
     {:features [0.15 0.25] :label 0}
     {:features [0.85 0.75] :label 1}])

  (def test-data
    [{:features [0.12 0.18] :label 0}
     {:features [0.88 0.82] :label 1}
     {:features [0.3 0.2] :label 0}
     {:features [0.7 0.9] :label 1}])

  ;; Step 3: Create a QNN network configuration
  ;; Using a feedforward architecture with 2 qubits
  (def qnn-network
    (create-feedforward-qnn
     2                           ; num-qubits
     2                           ; hidden-layers
     :feature-map-type :angle    ; angle encoding for input
     :activation-type :quantum-tanh))

  ;; Step 4: Analyze the network structure
  (def network-analysis (analyze-qnn-network qnn-network))
  network-analysis
  ;; => {:network-structure {:depth 8
  ;;                         :total-qubits 2
  ;;                         :total-parameters 18
  ;;                         :layer-composition {:input 1, :dense 2, :entangling 2, :activation 2, :measurement 1}}
  ;;     :layer-analysis [{:layer-index 0, :layer-type :input, :num-qubits 2, :parameter-count 0}
  ;;                       {:layer-index 1, :layer-type :dense, :num-qubits 2, :parameter-count 6}
  ;;                       ...]}

  ;; Step 5: Visualize the network
  (println (visualize-qnn-network qnn-network))
  ;; => QNN Network Visualization with emojis and layer details

  ;; Step 6: Create initial parameters (random)
  ;; NOTE: Use the correct path to get total parameters from network-structure
  (def num-params (get-in network-analysis [:network-structure :total-parameters]))
  (def initial-params
    (vec (repeatedly num-params #(* 2 Math/PI (rand)))))

  ;; Step 7: Test forward pass with initial parameters
  (def test-circuit
    (apply-qnn-network qnn-network [0.5 0.5] initial-params))
  
  (def test-result
    (qnn-forward-pass
     qnn-network
     [0.5 0.5]
     initial-params
     backend
     :options {:shots 1024
               :task-type :classification}))

  ;; Helper to extract prediction from simulator result format
  ;; The ideal-simulator returns results in :results :measurement-results :frequencies
  (defn extract-prediction-from-simulator-result
    "Extract most probable state from ideal-simulator result format"
    [result]
    (let [frequencies (get-in result [:results :measurement-results :frequencies])]
      (when (and frequencies (seq frequencies))
        (let [[max-state _max-count] (apply max-key val frequencies)
              num-qubits (get-in result [:results :circuit :num-qubits] 2)
              format-str (str "%" num-qubits "s")]
          (str/replace
           (format format-str (Integer/toBinaryString max-state))
           " " "0")))))

  ;; Extract prediction from result
  (def test-prediction
    (extract-prediction-from-simulator-result test-result))
  test-prediction
  ;; => "10" or "00" or "01" or "11" (bitstring)

  ;; Check the full result structure
  (keys test-result)
  ;; => (:job-status :results :execution-time-ms :job-id)
  
  (keys (:results test-result))
  ;; => (:final-state :result-types :circuit :circuit-metadata :measurement-results)

  ;; Step 8: Explore measurement results
  (def measurement-results (get-in test-result [:results :measurement-results]))
  (:shot-count measurement-results)  ; => 1024
  (take 5 (:frequencies measurement-results))  ; => Sample of state frequencies

  ;; Step 9: Simple prediction without training
  ;; For a quick test, let's make predictions on training data with random parameters
  (defn simple-predict [features params]
    (let [result (qnn-forward-pass qnn-network features params backend
                                   :options {:shots 512})]
      (extract-prediction-from-simulator-result result)))

  (simple-predict [0.1 0.2] initial-params)  ; => "10" (example output)
  (simple-predict [0.8 0.9] initial-params)  ; => "01" (example output)

  ;; Step 10: Analyze circuit properties
  (def circuit-info
    {:num-qubits (:num-qubits test-circuit)
     :num-operations (count (:operations test-circuit))
     :circuit-name (:name test-circuit)})
  circuit-info
  ;; => {:num-qubits 2, :num-operations 20, :circuit-name "QNN Forward Pass"}

  ;; Step 11: Custom network architecture example
  (def custom-network
    (let [input-layer {:layer-type :input
                       :num-qubits 3
                       :parameter-count 0
                       :feature-map-type :amplitude}
          
          dense-1 {:layer-type :dense
                   :num-qubits 3
                   :parameter-count 9}
          
          entangling-1 {:layer-type :entangling
                        :num-qubits 3
                        :parameter-count 2
                        :entangling-pattern :circular}
          
          activation-1 {:layer-type :activation
                        :num-qubits 3
                        :parameter-count 3
                        :activation-type :pauli-rotation}
          
          output-layer {:layer-type :measurement
                        :num-qubits 3
                        :parameter-count 0
                        :measurement-basis :computational}
          
          network [input-layer dense-1 entangling-1 activation-1 output-layer]
          allocated (allocate-parameters network)]
      (:network allocated)))

  ;; Validate custom network
  (s/valid? ::qnn-network custom-network)
  ;; => true

  ;; Analyze custom network
  (def custom-analysis (analyze-qnn-network custom-network))
  (get-in custom-analysis [:network-structure :total-parameters])
  ;; => 21 (9 dense + 2 entangling + 9 pauli-rotation + 1 for circular entangling)

  (println (visualize-qnn-network custom-network))
  ;; => Visualization of custom 3-qubit network

  ;; Step 12: Parameter inspection helpers
  (defn get-layer-params [network param-vec layer-idx]
    (let [layer (nth network layer-idx)]
      (extract-layer-parameters layer param-vec)))

  ;; Get parameters for first dense layer (index 1)
  (get-layer-params qnn-network initial-params 1)
  ;; => [param1 param2 param3 param4 param5 param6] (6 rotation angles)

  ;; Step 13: Compare different activation functions
  (defn create-network-with-activation [activation-type]
    (create-feedforward-qnn 2 1 
                            :feature-map-type :angle
                            :activation-type activation-type))

  (def qnn-tanh (create-network-with-activation :quantum-tanh))
  (def qnn-relu (create-network-with-activation :quantum-relu))
  (def qnn-pauli (create-network-with-activation :pauli-rotation))

  ;; Compare parameter counts
  (map #(get-in (analyze-qnn-network %) [:network-structure :total-parameters])
       [qnn-tanh qnn-relu qnn-pauli])
  ;; => (9 9 13) - pauli-rotation uses more parameters (3 per qubit vs 1)

  ;; End of working QNN example
  ;; 

  )
